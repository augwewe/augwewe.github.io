export const data = JSON.parse("{\"key\":\"v-6499c3b0\",\"path\":\"/Blog/2022/Crawl/foundation/Book1.html\",\"title\":\"百度新闻爬取\",\"lang\":\"zh-CN\",\"frontmatter\":{\"title\":\"百度新闻爬取\",\"date\":\"2022-10-30T12:04:21.000Z\",\"author\":\"cava\",\"isOriginal\":true,\"category\":[\"notebook\"],\"tag\":[\"爬虫技术\",\"爬虫实战\"],\"icon\":\"vue\",\"sticky\":false,\"star\":false,\"article\":true,\"timeline\":true,\"image\":false,\"navbar\":true,\"sidebarIcon\":true,\"headerDepth\":5,\"comment\":true,\"lastUpdated\":true,\"editLink\":false,\"backToTop\":true,\"toc\":true,\"description\":\"百度新闻网站爬取 流程图 import re,requests,tldextract,time def save_data(url,html): print(\\\"%s :%s\\\" %(url,len(html))) def crawler(): #1.下载百度页面 hub_url='https://news.baidu.com/' req=requests.get(hub_url) html=req.text # print(html) #2.获取新闻链接 # pattern='.*?&lt;link.*?href=\\\"(.*?)\\\".*?style=\\\"zoom.*?&gt;.*?id=\\\"ariaTipText\\\".*?href=\\\"\\\"' pattern=r'href=[\\\\'\\\"]?(.*?)[\\\\'\\\"\\\\s]' news_links=re.findall(pattern,html) # print(news_links) #3.过滤链接 links_lst=[] for i in news_links: if not i.starswith('https'): continue tld=tldextract.extract(i) if tld.domain == 'baidu': continue links_lst.append(i) for k in links_lst: html=requests.get(k).text def main(): while 1: crawler() time.sleep() if __name__ == '__main__': crawler()\",\"head\":[[\"meta\",{\"property\":\"og:url\",\"content\":\"https://augwewe.cn/Blog/2022/Crawl/foundation/Book1.html\"}],[\"meta\",{\"property\":\"og:site_name\",\"content\":\"augwewe\"}],[\"meta\",{\"property\":\"og:title\",\"content\":\"百度新闻爬取\"}],[\"meta\",{\"property\":\"og:description\",\"content\":\"百度新闻网站爬取 流程图 import re,requests,tldextract,time def save_data(url,html): print(\\\"%s :%s\\\" %(url,len(html))) def crawler(): #1.下载百度页面 hub_url='https://news.baidu.com/' req=requests.get(hub_url) html=req.text # print(html) #2.获取新闻链接 # pattern='.*?&lt;link.*?href=\\\"(.*?)\\\".*?style=\\\"zoom.*?&gt;.*?id=\\\"ariaTipText\\\".*?href=\\\"\\\"' pattern=r'href=[\\\\'\\\"]?(.*?)[\\\\'\\\"\\\\s]' news_links=re.findall(pattern,html) # print(news_links) #3.过滤链接 links_lst=[] for i in news_links: if not i.starswith('https'): continue tld=tldextract.extract(i) if tld.domain == 'baidu': continue links_lst.append(i) for k in links_lst: html=requests.get(k).text def main(): while 1: crawler() time.sleep() if __name__ == '__main__': crawler()\"}],[\"meta\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"meta\",{\"property\":\"og:locale\",\"content\":\"zh-CN\"}],[\"meta\",{\"property\":\"article:author\",\"content\":\"cava\"}],[\"meta\",{\"property\":\"article:tag\",\"content\":\"爬虫技术\"}],[\"meta\",{\"property\":\"article:tag\",\"content\":\"爬虫实战\"}],[\"meta\",{\"property\":\"article:published_time\",\"content\":\"2022-10-30T12:04:21.000Z\"}],[\"script\",{\"type\":\"application/ld+json\"},\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Article\\\",\\\"headline\\\":\\\"百度新闻爬取\\\",\\\"image\\\":[\\\"\\\"],\\\"datePublished\\\":\\\"2022-10-30T12:04:21.000Z\\\",\\\"dateModified\\\":null,\\\"author\\\":[{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"cava\\\"}]}\"]]},\"headers\":[{\"level\":2,\"title\":\"百度新闻网站爬取\",\"slug\":\"百度新闻网站爬取\",\"link\":\"#百度新闻网站爬取\",\"children\":[{\"level\":3,\"title\":\"流程图\",\"slug\":\"流程图\",\"link\":\"#流程图\",\"children\":[]},{\"level\":3,\"title\":\"补充：tldextract\",\"slug\":\"补充-tldextract\",\"link\":\"#补充-tldextract\",\"children\":[]}]}],\"readingTime\":{\"minutes\":1.24,\"words\":371},\"filePathRelative\":\"Blog/2022/Crawl/foundation/Book1.md\",\"localizedDate\":\"2022年10月30日\",\"excerpt\":\"<h2> 百度新闻网站爬取</h2>\\n<h3> 流程图</h3>\\n\\n<div class=\\\"language-python line-numbers-mode\\\" data-ext=\\\"py\\\"><pre class=\\\"language-python\\\"><code><span class=\\\"token keyword\\\">import</span> re<span class=\\\"token punctuation\\\">,</span>requests<span class=\\\"token punctuation\\\">,</span>tldextract<span class=\\\"token punctuation\\\">,</span>time\\n\\n<span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">save_data</span><span class=\\\"token punctuation\\\">(</span>url<span class=\\\"token punctuation\\\">,</span>html<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n    <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"%s :%s\\\"</span> <span class=\\\"token operator\\\">%</span><span class=\\\"token punctuation\\\">(</span>url<span class=\\\"token punctuation\\\">,</span><span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>html<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">crawler</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n    <span class=\\\"token comment\\\">#1.下载百度页面</span>\\n    hub_url<span class=\\\"token operator\\\">=</span><span class=\\\"token string\\\">'https://news.baidu.com/'</span>\\n    req<span class=\\\"token operator\\\">=</span>requests<span class=\\\"token punctuation\\\">.</span>get<span class=\\\"token punctuation\\\">(</span>hub_url<span class=\\\"token punctuation\\\">)</span>\\n    html<span class=\\\"token operator\\\">=</span>req<span class=\\\"token punctuation\\\">.</span>text\\n    <span class=\\\"token comment\\\"># print(html)</span>\\n\\n    <span class=\\\"token comment\\\">#2.获取新闻链接</span>\\n    <span class=\\\"token comment\\\"># pattern='.*?&lt;link.*?href=\\\"(.*?)\\\".*?style=\\\"zoom.*?&gt;.*?id=\\\"ariaTipText\\\".*?href=\\\"\\\"'</span>\\n    pattern<span class=\\\"token operator\\\">=</span><span class=\\\"token string\\\">r'href=[\\\\'\\\"]?(.*?)[\\\\'\\\"\\\\s]'</span>\\n    news_links<span class=\\\"token operator\\\">=</span>re<span class=\\\"token punctuation\\\">.</span>findall<span class=\\\"token punctuation\\\">(</span>pattern<span class=\\\"token punctuation\\\">,</span>html<span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># print(news_links)</span>\\n\\n    <span class=\\\"token comment\\\">#3.过滤链接</span>\\n    links_lst<span class=\\\"token operator\\\">=</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">]</span>\\n    <span class=\\\"token keyword\\\">for</span> i <span class=\\\"token keyword\\\">in</span> news_links<span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token keyword\\\">if</span> <span class=\\\"token keyword\\\">not</span> i<span class=\\\"token punctuation\\\">.</span>starswith<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'https'</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n            <span class=\\\"token keyword\\\">continue</span>\\n        tld<span class=\\\"token operator\\\">=</span>tldextract<span class=\\\"token punctuation\\\">.</span>extract<span class=\\\"token punctuation\\\">(</span>i<span class=\\\"token punctuation\\\">)</span>\\n        <span class=\\\"token keyword\\\">if</span> tld<span class=\\\"token punctuation\\\">.</span>domain <span class=\\\"token operator\\\">==</span> <span class=\\\"token string\\\">'baidu'</span><span class=\\\"token punctuation\\\">:</span>\\n            <span class=\\\"token keyword\\\">continue</span>\\n        links_lst<span class=\\\"token punctuation\\\">.</span>append<span class=\\\"token punctuation\\\">(</span>i<span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token keyword\\\">for</span> k <span class=\\\"token keyword\\\">in</span> links_lst<span class=\\\"token punctuation\\\">:</span>\\n        html<span class=\\\"token operator\\\">=</span>requests<span class=\\\"token punctuation\\\">.</span>get<span class=\\\"token punctuation\\\">(</span>k<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>text\\n\\n<span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">main</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n    <span class=\\\"token keyword\\\">while</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">:</span>\\n        crawler<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n        time<span class=\\\"token punctuation\\\">.</span>sleep<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token keyword\\\">if</span> __name__ <span class=\\\"token operator\\\">==</span> <span class=\\\"token string\\\">'__main__'</span><span class=\\\"token punctuation\\\">:</span>\\n    crawler<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre><div class=\\\"line-numbers\\\" aria-hidden=\\\"true\\\"><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div><div class=\\\"line-number\\\"></div></div></div>\",\"autoDesc\":true}")

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
